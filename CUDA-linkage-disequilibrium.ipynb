{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1A/cO1btvksxMkRuPeTYP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tpet93/CUDA-linkage-disequilibrium/blob/master/CUDA-linkage-disequilibrium.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WugIit8piInN",
        "colab_type": "text"
      },
      "source": [
        "Made to replicate the results of\n",
        "allel.rogers_huff_r() in scikit-allel.\n",
        "\n",
        "\n",
        "Modifications include returning r^2 and the option to return a running mean.\n",
        "This second option allows for arbtrarilly large dataset at the cost of being able to calculate std-dev and similar parameters on the output.\n",
        "\n",
        "Input is\n",
        "Diploid genotypes at biallelic variants, coded as the number of alternate alleles per call (i.e., 0 = hom ref, 1 = het, 2 = hom alt).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrGn0pMlhw3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this to find out how much GPU Memory you have been allocated, this lets us use as much as possible.\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbpJhZLAjI04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "# from tqdm import tqdm\n",
        "\n",
        "from numba import jit\n",
        "import time\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNQ_ejxUjN19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# returns each r for a given set of pairs\n",
        "def r_torch(x,y,cudatype):    \n",
        "\n",
        "    #incase single pair is passed\n",
        "    if len(x.shape)== 1:\n",
        "        x = x.unsqueeze(dim = 0)\n",
        "        y = y.unsqueeze(dim = 0)\n",
        "    \n",
        "    # we want to consider negative values as missing.\n",
        "    # generate a mask of all non missing pairs\n",
        "    mask = (x>=0) & (y>=0)\n",
        "\n",
        "\n",
        "    #if we remove missing values from our tensor with the mask them we loose our array dimensions.\n",
        "\n",
        "    #we can expoit the fact that the absolute values of our numbers do not affect our correlation coeficient implementation.\n",
        "    #therefore: we can shift our inputs by + 1, this way missing pairs can be set to zero and not affect our sums.\n",
        "\n",
        "    #shift all by one to make room for missing avlues to be zero\n",
        "    x= x+1 \n",
        "    y= y+1\n",
        "    \n",
        "    #set both elements to zero if one or both are missing.\n",
        "    x[~mask]= 0 \n",
        "    y[~mask]= 0\n",
        "    \n",
        "    #x - mean of x (ignoring missing values)\n",
        "    vx = x.T-(torch.sum(x,dim =1).type(cudatype)/torch.sum(mask,dim =1))\n",
        "    vy = y.T-(torch.sum(y,dim =1).type(cudatype)/torch.sum(mask,dim =1))\n",
        "\n",
        "    #transpose\n",
        "    vx = vx.T\n",
        "    vy = vy.T\n",
        "\n",
        "    #keep missing values at zero\n",
        "    vx[~mask] = 0\n",
        "    vy[~mask] = 0\n",
        "\n",
        "    #calculate covariance\n",
        "    cov = torch.sum(torch.mul(vx,vy),dim = 1)\n",
        "\n",
        "\n",
        "    svx2 = torch.sqrt(torch.sum(vx ** 2,dim =1))\n",
        "    svy2 = torch.sqrt(torch.sum(vy ** 2,dim =1))\n",
        "    \n",
        "    #Correlation Coefficient\n",
        "    r = torch.div(cov,torch.mul(svx2,svy2))\n",
        "  \n",
        "    #Return r\n",
        "    return(r)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeVs_2LZjN5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "The below functions replicates torch.combinations()\n",
        "however it is written in a way that combinations can be retrieved form any theoretical position and length without need to calcuate the entire tensor as it may be billions long.\n",
        "combinations = makecombs(n)\n",
        "is equivalent to\n",
        "combinations = torch.combinations(torch.arange(n))\n",
        "'''\n",
        "\n",
        "#block number is the first member\n",
        "@jit(nopython=True)\n",
        "def getblocknumbyidx(n,idx):\n",
        "    n2 = n - .5\n",
        "    blocknum = ((n2) - np.sqrt((n2**2)-2*idx))\n",
        "    return blocknum\n",
        "\n",
        "@jit(nopython=True) \n",
        "def blocksize(n,blockn):\n",
        "    return n-1-blockn\n",
        "\n",
        "#makecombs(500,1000,2000)\n",
        "#returns torch.combinations(torch.arange(500))[1000,2000]\n",
        "\n",
        "@jit(nopython=True) \n",
        "def makecombs(n,starti = 0,endi = 0):\n",
        "    size = n*(n-1)//2# size of all pairs\n",
        "    if endi == 0:\n",
        "        endi = size\n",
        "    endi = min(endi,size)\n",
        "    #get request output size and init tensor of zeros\n",
        "    out = np.zeros((endi-starti,2))\n",
        "    # each requested output pair calcuate foirst and second members\n",
        "    for i in range(starti,endi):\n",
        "        b = getblocknumbyidx(n,i)#block number is the first member\n",
        "        bn = b//1 #reduce to floor integer\n",
        "\n",
        "        res = b % 1 # get leftover residual after removing integer value\n",
        "        #this residual represents the proportion of the second value along its range.\n",
        "        #i,e 0.99 would indicate the second member is close to its maximum value for this block\n",
        "        bindex = (res*blocksize(n,bn)+bn+1.5)//1\n",
        "        #the math is a bit weird here but this effectivly converts the residual into the second member.\n",
        "        out[i-starti] = bn,bindex\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdGnbLHQtxrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "batch_r2 splits the input data into batches to fit on a given amount of GPU RAM\n",
        "fp16 is a bit faster but results differ slightly from fp32\n",
        "ret_mean tracks a running mean of each batch allowing arbitraily large input datsets.\n",
        "if false it will return an r2 value for each pair (this may be several billion r2 values)\n",
        "'''\n",
        "def batch_r2(gn,RamGB=15.0,fp16=True,ret_mean = False,r_squared = True):\n",
        "\n",
        "\n",
        "\n",
        "    if fp16:\n",
        "        cudatype = torch.cuda.HalfTensor\n",
        "        cputype = torch.HalfTensor\n",
        "        byte_per_snp = 38 #found from trial and error\n",
        "    else:\n",
        "        cudatype = torch.cuda.FloatTensor\n",
        "        cputype = torch.FloatTensor\n",
        "        byte_per_snp = 76  #found from trial and error\n",
        "\n",
        "\n",
        "    #largest batch we can fit on GPU memory\n",
        "    batchsize = int((RamGB * 1e9 / (gn.shape[1]*byte_per_snp)))\n",
        "\n",
        "    starttime = time.time()\n",
        "    y_shape = gn.shape[0]\n",
        "\n",
        "    combinations_size = y_shape*(y_shape-1)//2\n",
        "    print(combinations_size, \"pairs\")\n",
        "\n",
        "    num_batches = np.ceil(combinations_size/batchsize).astype(int)\n",
        "\n",
        "    if ret_mean:\n",
        "        r2sum = 0\n",
        "        r2size = 0\n",
        "    else:\n",
        "        #store returned r2 values in cpu RAM\n",
        "        r2s = torch.zeros(0).type(cputype)\n",
        "\n",
        "\n",
        "    for batch in tqdm(range(num_batches)):\n",
        "\n",
        "        batchstart = batch*batchsize\n",
        "        batchend = batchstart+batchsize\n",
        "\n",
        "        #get pair combinations for current batch\n",
        "        batchcomb = makecombs(y_shape,batchstart,batchend)\n",
        "\n",
        "        xslice = gn[batchcomb[:,0]]\n",
        "        yslice = gn[batchcomb[:,1]]\n",
        "\n",
        "        #calcutlate r2 values\n",
        "        if r_squared:\n",
        "            r2 = (r_torch(xslice,yslice,cudatype)**2).cpu()\n",
        "        else:\n",
        "            r2 = r_torch(xslice,yslice,cudatype).cpu()\n",
        "\n",
        "\n",
        "\n",
        "        if ret_mean:       \n",
        "            #do running mean\n",
        "            r2 = r2.float()\n",
        "            nan_array = torch.isnan(r2) #remove Nan R Values\n",
        "            r2 = r2[~ nan_array] #remove Nan R Values\n",
        "            r2sum = r2sum + np.sum(r2.numpy())\n",
        "            r2size = r2size + r2.shape[0]\n",
        "\n",
        "        else:\n",
        "            #add results to list\n",
        "            r2s = torch.cat((r2s, r2), 0)\n",
        "\n",
        "    print('Calculating R2 took ',time.time()-starttime,'Seconds')\n",
        "\n",
        "    if ret_mean:\n",
        "        return r2sum/r2size\n",
        "    else:\n",
        "        return r2s\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPXsAnvpjN81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import glob\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10ZUH0o0wwwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LDNE: a program for estimating effective population size from data on linkage disequilibrium\n",
        "#ROBIN  S. WAPLES and CHI DO 2008\n",
        "\n",
        "def r2_to_Ne(r2,S):\n",
        "    print(\"r2\",r2)\n",
        "\n",
        "    E = 1/S +3.19/(S**2)\n",
        "    r2m = r2-E\n",
        "    print(\"Num_Samples\",S)\n",
        "\n",
        "    # adding complex values as it avoids errors when tring to get square roots of negatives\n",
        "    ne = (0.308+np.sqrt((0.308**2+0j)- 2.08*r2m)) / (2*r2m)\n",
        "    print(\"ne_raw over 30:\",ne)\n",
        "\n",
        "    ne2 = ((1/3.)+np.sqrt((1/9.)- 2.76*r2m+0j)) / (2*r2m)\n",
        "    print(\"ne_raw under 30:\",ne2)\n",
        "\n",
        "    nc =11\n",
        "    pne_ovene = 0.098+0.219*np.log(nc)\n",
        "    print(\"p over ne :\",pne_ovene)\n",
        "\n",
        "    print(\"Ne under 30:\",ne2/pne_ovene)\n",
        "    print(\"Ne over 30:\",ne/pne_ovene)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rvcE8jzkb1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate dummy data and run with mean\n",
        "gn = torch.randint(-1, 3, (5000,100)).type(torch.cuda.CharTensor)\n",
        "print(gn.shape)\n",
        "r2 = batch_r2(gn,RamGB=15,fp16=False,ret_mean=True)\n",
        "\n",
        "\n",
        "r2_to_Ne(r2,gn.shape[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLPK_mfpwfJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate dummy data and run without mean and fp16\n",
        "r2s = batch_r2(gn,RamGB=15,fp16=True,ret_mean=False)\n",
        "\n",
        "nan_array = torch.isnan(r2s.float().cpu()) #remove Nan R Values\n",
        "data = r2s[~ nan_array] #remove Nan R Values\n",
        "\n",
        "print('std dev ',torch.std(data.float()).cpu().numpy())\n",
        "\n",
        "r2m = np.mean(data.cpu().numpy())\n",
        "r2_to_Ne(r2,gn.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O16DgkKqwfMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import CSV\n",
        "\n",
        "#currently set up for Samples on rows SNPs on columns\n",
        "\n",
        "#Batch calc\n",
        "datalist = glob.glob('*.csv') \n",
        "for dataset in datalist:\n",
        "    \n",
        "    df = pd.read_csv(dataset).fillna(-1)## fill na values with -1\n",
        "    gn = torch.tensor(df[df.columns[1:]].values).T.type(torch.cuda.CharTensor) # discard non value entries and covert to cuda int8\n",
        "\n",
        "    r2 = batch_r2(gn,RamGB=15,fp16=False,ret_mean=True)\n",
        "    print ('-'*10,'Done with ',dataset,' ','-'*10)\n",
        "    r2_to_Ne(r2,gn.shape[1])\n",
        "    print ('-'*10,'-'*10)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfByzwYki_Cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#comparison test below\n",
        "!pip install scikit-allel\n",
        "import allel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7kNxi251Xwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compare torch r to scikit allel\n",
        "\n",
        "#generate dummy data\n",
        "gn = torch.randint(-1, 3, (5000,100)).type(torch.cuda.CharTensor)\n",
        "\n",
        "\n",
        "starttime = time.time()\n",
        "rs = batch_r2(gn,RamGB=15,fp16=False,ret_mean=False,r_squared=False)\n",
        "print('Torch r Took: ',time.time()-starttime,'Seconds')\n",
        "\n",
        "starttime = time.time()\n",
        "rorig =allel.rogers_huff_r(gn.cpu().numpy())\n",
        "print('SciKit allele Took: ',time.time()-starttime,'Seconds')\n",
        "\n",
        "\n",
        "rorigt = torch.tensor(rorig)\n",
        "\n",
        "np.testing.assert_allclose(rorigt,rs,rtol=1e-5, atol=1e-5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1UoJ-n71X4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vTE_CuJ1X0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}